var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = PIQL","category":"page"},{"location":"#PIQL","page":"Home","title":"PIQL","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for PIQL.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [PIQL]","category":"page"},{"location":"#PIQL.ControlProblem","page":"Home","title":"PIQL.ControlProblem","text":"ControlProblem is a struct with fields that are      the functions which completely define a KL-control problem\n\n\n\n\n\n","category":"type"},{"location":"#PIQL.empty_actor-Tuple{}","page":"Home","title":"PIQL.empty_actor","text":"We define an actor interface: an actor is a callable struct\n\nstruct GenericActor     parameters\n\nend\n\nfunction (a::Actor)(state,action)     ...     return E_actor end\n\nfunction loss(actor, minibatch)     ...     return E_actor end\n\n\n\n\n\n","category":"method"},{"location":"#PIQL.intial_state_action-Tuple{ControlProblem, Any}","page":"Home","title":"PIQL.intial_state_action","text":"Start off a trajectory with a new state action pair\n\n\n\n\n\n","category":"method"},{"location":"#PIQL.performance_estimate-Tuple{Any, Any}","page":"Home","title":"PIQL.performance_estimate","text":"Monte Carlo estimate for the performance of our state.\n\n\n\n\n\n","category":"method"},{"location":"#PIQL.step_choices-Tuple{}","page":"Home","title":"PIQL.step_choices","text":"Actions are indexed by natural numbers\n\n\n\n\n\n","category":"method"},{"location":"#PIQL.train!-Tuple{TabularActor, Any}","page":"Home","title":"PIQL.train!","text":"Destructive memory training, storing partition function memory is composed of struct (at time of writing) consisting of\n\nstruct EnergyEstimate{S,A}     state::S     action::A     Î²::Float64     xi::Float64 # energy fluctuation realization     logz::Float64 end \n\n\n\n\n\n","category":"method"}]
}
